{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal MultiCapa, OOP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_images import get_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST path\n",
    "mnist_path = './mnist_raw/'\n",
    "x_train_num, y_train_num, x_test_num, y_test_num = get_images(mnist_path)\n",
    "\n",
    "x_train = x_train_num[:50000].reshape(50000, -1).astype(float)\n",
    "y_train = y_train_num[:50000].reshape(50000, 1)\n",
    "\n",
    "x_val = x_train_num[50000:].reshape(10000, -1).astype(float)\n",
    "y_val = y_train_num[50000:].reshape(10000, 1)\n",
    "\n",
    "x_test = x_test_num.copy().reshape(10000, -1).astype(float)\n",
    "y_test = y_test_num.copy().reshape(10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33.39512885204082, 78.6661972212754, 0.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std(), x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x_mean, x_std, x_data):\n",
    "    return (x_data - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train = normalise(x_mean, x_std, x_train)\n",
    "x_val = normalise(x_mean, x_std, x_val)\n",
    "x_test = normalise(x_mean, x_std, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-9.646705203355238e-18, 0.9999999999999997)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(image):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen muestreada representa un: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnd_idx = np.random.randint(len(y_test))\n",
    "print(f'La imagen muestreada representa un: {y_test[rnd_idx, 0]}')\n",
    "plot_number(x_test_num[rnd_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecuaciones para nuestro modelo\n",
    "\n",
    "\n",
    "$$z^1 = W^1 X + b^1$$\n",
    "\n",
    "$$a^1 = ReLU(z^1) $$\n",
    "\n",
    "$$z^2 = W^2 a^1 + b^2$$\n",
    "\n",
    "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones adicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(mb_size, x, y, shuffle = True):\n",
    "    '''\n",
    "    x  #muestras, 784\n",
    "    y #muestras, 1\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle: \n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]  \n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuestra clase Linear, ReLU y Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos permite agregar atributos como el gradiente.\n",
    "class np_tensor(np.ndarray): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Clase Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     1,
     7,
     10
    ]
   },
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        '''\n",
    "        Init parameters utilizando Kaiming He\n",
    "        '''\n",
    "        self.W = (np.random.randn(output_size, input_size) / np.sqrt(input_size / 2)).view(np_tensor)\n",
    "        # view(np_tensor), genera una vista del arreglo\n",
    "        self.b = (np.zeros((output_size, 1))).view(np_tensor)\n",
    "    \n",
    "    # dunder __func__\n",
    "    # Llama de forma automática esa función sin tener que escribirla.\n",
    "    def __call__(self, X): # este es el foward de la clase lineal\n",
    "        Z = self.W @ X + self.b\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, X, Z):\n",
    "        X.grad = self.W.T @ Z.grad\n",
    "        self.W.grad = Z.grad @ X.T\n",
    "        self.b.grad = np.sum(Z.grad, axis = 1, keepdims=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     1,
     3
    ]
   },
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __call__(self, Z):\n",
    "        return np.maximum(0, Z)\n",
    "    def backward(self, Z, A):\n",
    "        Z.grad = A.grad.copy()\n",
    "        Z.grad[Z <= 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     23
    ]
   },
   "outputs": [],
   "source": [
    "class Sequential_layers():\n",
    "    def __init__(self, layers):\n",
    "        '''\n",
    "        layers - lista que contiene objetos de tipo Linear, ReLU\n",
    "        '''\n",
    "        self.layers = layers\n",
    "        self.x = None\n",
    "        self.outputs = {}\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        self.x = X \n",
    "        self.outputs['l0'] = self.x\n",
    "        for i, layer in enumerate(self.layers, 1):\n",
    "            self.x = layer(self.x)\n",
    "            self.outputs['l'+str(i)]=self.x\n",
    "        return self.x\n",
    "    \n",
    "    def backward(self):\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            self.layers[i].backward(self.outputs['l'+str(i)], self.outputs['l'+str(i+1)])\n",
    "    \n",
    "    def update(self, learning_rate = 1e-3):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, ReLU): continue\n",
    "            layer.W = layer.W - learning_rate * layer.W.grad\n",
    "            layer.b = layer.b - learning_rate * layer.b.grad\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.__call__(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def softmaxXEntropy(x, y):\n",
    "    batch_size = x.shape[1]\n",
    "    exp_scores = np.exp(x)\n",
    "    probs = exp_scores / exp_scores.sum(axis = 0)\n",
    "    preds = probs.copy()\n",
    "    # Costo\n",
    "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
    "    cost = np.sum(-np.log(y_hat)) / batch_size\n",
    "    # Calcular gradientes\n",
    "    probs[y.squeeze(), np.arange(batch_size)] -= 1 #dl/dx\n",
    "    x.grad = probs.copy()\n",
    "    \n",
    "    return preds, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, mb_size=128, learning_rate = 1e-3):\n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y) in enumerate(create_minibatches(mb_size, x_train, y_train)):\n",
    "            scores = model(x.T.view(np_tensor))\n",
    "            _, cost = softmaxXEntropy(scores, y)\n",
    "            model.backward()\n",
    "            model.update(learning_rate)\n",
    "        print(f'costo: {cost}, accuracy: {accuracy(x_val, y_val, mb_size)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def accuracy(x, y, mb_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (x, y) in enumerate(create_minibatches(mb_size, x, y)):\n",
    "        pred = model(x.T.view(np_tensor))\n",
    "        correct += np.sum(np.argmax(pred, axis=0) == y.squeeze())\n",
    "        total += pred.shape[1]\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential_layers([Linear(784, 200), ReLU(), Linear(200, 200), ReLU(), Linear(200, 10)])\n",
    "mb_size = 512\n",
    "learning_rate = 1e-4\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costo: 0.31428084971843534, accuracy: 0.9199\n",
      "costo: 0.2240248227253503, accuracy: 0.939\n",
      "costo: 0.27447825046722263, accuracy: 0.9468\n",
      "costo: 0.1507111829618196, accuracy: 0.9536\n",
      "costo: 0.1744406726408902, accuracy: 0.9578\n",
      "costo: 0.11727143457038272, accuracy: 0.9597\n",
      "costo: 0.09895815888976645, accuracy: 0.962\n",
      "costo: 0.12852873932963313, accuracy: 0.9642\n",
      "costo: 0.0948266430317151, accuracy: 0.9654\n",
      "costo: 0.09820020120271636, accuracy: 0.9668\n",
      "costo: 0.1244498539796802, accuracy: 0.9676\n",
      "costo: 0.09439103703538418, accuracy: 0.9682\n",
      "costo: 0.1157993710137003, accuracy: 0.9705\n",
      "costo: 0.05488877674078158, accuracy: 0.97\n",
      "costo: 0.06432565405238043, accuracy: 0.9694\n",
      "costo: 0.053348733978357925, accuracy: 0.9715\n",
      "costo: 0.06575550521357121, accuracy: 0.9714\n",
      "costo: 0.06245073921654418, accuracy: 0.9723\n",
      "costo: 0.08288523302286654, accuracy: 0.9715\n",
      "costo: 0.06950276486642502, accuracy: 0.973\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs, mb_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9738\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(x_test, y_test, mb_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el valor predicho es: 8, el valor real es:8\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(y_test))\n",
    "plot_number(x_test_num[idx])\n",
    "pred = model.predict(x_test[idx].reshape(-1, 1))\n",
    "print(f'el valor predicho es: {pred}, el valor real es:{y_test[idx][0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
